# âœ‹ Sign Language Detection ğŸ¤Ÿ

## ğŸŒŸ Overview
This project implements a sign language detection system using computer vision and deep learning. It captures hand gestures via a webcam, processes the images, and classifies them into predefined sign language gestures. The system uses OpenCV for image processing, MediaPipe for hand tracking, and TensorFlow/Keras for classification.

![Screenshot 2025-02-05 133433](https://github.com/user-attachments/assets/f8b1e338-7127-41ca-86fb-573973ed7c9d)

## ğŸš€ Features
- ğŸ¥ **Real-time Sign Language Detection**: Uses a webcam to detect and classify hand signs.
- âœ‹ **Hand Tracking**: Utilizes MediaPipe-based hand detection.
- ğŸ§  **Sign Classification**: Employs a trained deep learning model to classify hand gestures.
- ğŸŒ **Web Interface**: Provides a Flask-based web application for ease of use.
- ğŸ–¼ **Image Processing**: Crops and resizes hand regions for better model accuracy.

## ğŸ“‚ Project Structure
- ğŸ—‚ `datacollection.py`: Captures hand gesture images and stores them for training.
- ğŸ–¥ `test.py`: Runs the Flask web application for real-time detection.
- ğŸ“œ `versions_needed.txt`: Lists required dependencies and their versions.

## ğŸ›  Installation
### Prerequisites
Ensure you have Python installed (required: Python 3.10).
Ensure you have Python installed (required: Python 3.10). Then, install the necessary dependencies:
```sh
pip install -r versions_needed.txt
```

## â–¶ï¸ Running the Project
### ğŸ“¸ Collect Training Data
Run the following command to start capturing hand images for training:
```sh
python datacollection.py
```
Press `s` to save images, and `Esc` to exit.

### ğŸŒ Start the Web Application
Run the Flask app for real-time sign detection:
```sh
python test.py
```
Access the web interface at `http://127.0.0.1:5000/`.

## ğŸ¯ Usage
- ğŸ“¹ **Live Video Mode**: Click "Start" on the web interface to begin sign detection.
- ğŸ“¤ **Upload Mode**: Upload an image to classify a sign.
- â¹ **Stop Detection**: Click "Stop" to end the detection session.

## ğŸ“¦ Dependencies
The following libraries are required:
- ğŸ”¢ TensorFlow 2.12.0
- ğŸ” Keras 2.12.0
- ğŸ“· OpenCV 4.8.0.76
- ğŸ– cvzone 1.5.6
- ğŸ– MediaPipe 0.10.0
- ğŸ”¢ NumPy, SciPy, Pillow, Matplotlib

## ğŸ”® Future Improvements
- â• Support for more sign language gestures.
- ğŸ¯ Enhance model accuracy with additional training data.
- ğŸ“± Implement a mobile-friendly UI.
- ğŸŒ Expand the dataset for multilingual sign recognition.

## â¤ï¸ Acknowledgments
This project is built using open-source technologies like OpenCV, MediaPipe, and TensorFlow. Special thanks to the open-source community for their contributions. ğŸ™Œ

